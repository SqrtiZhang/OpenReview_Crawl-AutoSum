,name,url,file_name,path
0,Jailbreaking Black Box Large Language Models in Twenty Queries,/attachment?id=hkjcdmz8Ro&name=pdf,JailbreakingBlackBoxLargeLanguageModelsinTwentyQueries.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
1,Quack: Automatic Jailbreaking Large Language Models via Role-playing,/attachment?id=1zt8GWZ9sc&name=pdf,QuackAutomaticJailbreakingLargeLanguageModelsviaRoleplaying.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
2,Generating Stealthy Jailbreak Prompts on Aligned Large Language Models,/attachment?id=7Jwpw4qKkb&name=pdf,GeneratingStealthyJailbreakPromptsonAlignedLargeLanguageModels.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
3,Jailbreaking Language Models at Scale via Persona Modulation,/attachment?id=gYa9R2Pmp8&name=pdf,JailbreakingLanguageModelsatScaleviaPersonaModulation.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
4,Universal Jailbreak Backdoors from Poisoned Human Feedback,/attachment?id=GxCGsxiAaK&name=pdf,UniversalJailbreakBackdoorsfromPoisonedHumanFeedback.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
5,SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks,/attachment?id=xq7h9nfdY2&name=pdf,SmoothLLMDefendingLargeLanguageModelsAgainstJailbreakingAttacks.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
6,Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models,/attachment?id=plmBsXHxgR&name=pdf,JailbreakinpiecesCompositionalAdversarialAttacksonMultiModalLanguageModels.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
7,Multilingual Jailbreak Challenges in Large Language Models,/attachment?id=vESNKdEMGp&name=pdf,MultilingualJailbreakChallengesinLargeLanguageModels.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
8,Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM,/attachment?id=V01FPV3SNY&name=pdf,DefendingAgainstAlignmentBreakingAttacksviaRobustlyAlignedLLM.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
9,AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models,/attachment?id=ZuZujQ9LJV&name=pdf,AutoDANAutomaticandInterpretableAdversarialAttacksonLargeLanguageModels.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
10,Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation,/attachment?id=r42tSSCHPh&name=pdf,CatastrophicJailbreakofOpensourceLLMsviaExploitingGeneration.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
11,Second-order Jailbreaks: Generative Agents Successfully Manipulate Through an Intermediary,/attachment?id=HPmhaOTseN&name=pdf,SecondorderJailbreaksGenerativeAgentsSuccessfullyManipulateThroughanIntermediary.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
12,Image Hijacks: Adversarial Images can Control Generative Models at Runtime,/attachment?id=ucMRo9IIC1&name=pdf,ImageHijacksAdversarialImagescanControlGenerativeModelsatRuntime.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
13,Open Sesame! Universal Black Box Jailbreaking of Large Language Models,/attachment?id=QXCjvHnDmu&name=pdf,OpenSesameUniversalBlackBoxJailbreakingofLargeLanguageModels.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
14,Visual Adversarial Examples Jailbreak Aligned Large Language Models,/attachment?id=cZ4j7L6oui&name=pdf,VisualAdversarialExamplesJailbreakAlignedLargeLanguageModels.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
15,"Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!",/attachment?id=hTEGyKf0dZ&name=pdf,"FinetuningAlignedLanguageModelsCompromisesSafety,EvenWhenUsersDoNotIntendTo.pdf",C:\Users\zhangyongting\Desktop\work\openreview\pdf
16,Detecting Language Model Attacks With Perplexity,/attachment?id=lNLVvdHyAw&name=pdf,DetectingLanguageModelAttacksWithPerplexity.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
17,GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher,/attachment?id=MbfAK4s61A&name=pdf,GPT4IsTooSmartToBeSafeStealthyChatwithLLMsviaCipher.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
18,Can Language Models be Instructed to Protect Personal Information?,/attachment?id=1vqHTUTod9&name=pdf,CanLanguageModelsbeInstructedtoProtectPersonalInformation.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
19,Baseline Defenses for Adversarial Attacks Against Aligned Language Models,/attachment?id=0VZP2Dr9KX&name=pdf,BaselineDefensesforAdversarialAttacksAgainstAlignedLanguageModels.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
20,On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs,/attachment?id=H3UayAQWoE&name=pdf,OntheHumanityofConversationalAIEvaluatingthePsychologicalPortrayalofLLMs.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
21,Fundamental Limitation of Alignment in Large Language Models,/attachment?id=4qFIkOhq24&name=pdf,FundamentalLimitationofAlignmentinLargeLanguageModels.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
22,Open-Source Can Be Dangerous: On the Vulnerability of Value Alignment in Open-Source LLMs,/attachment?id=NIouO0C0ex&name=pdf,OpenSourceCanBeDangerousOntheVulnerabilityofValueAlignmentinOpenSourceLLMs.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
23,Understanding Hidden Context in Preference Learning: Consequences for RLHF,/attachment?id=0tWTxYYPnW&name=pdf,UnderstandingHiddenContextinPreferenceLearningConsequencesforRLHF.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
24,(InThe)WildChat: 570K ChatGPT Interaction Logs In The Wild,/attachment?id=Bl8u7ZRlbM&name=pdf,InTheWildChat570KChatGPTInteractionLogsInTheWild.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
25,"Tricking LLMs into Disobedience: Understanding, Analyzing, and Preventing Jailbreaks",/attachment?id=I0xugUnvVzK&name=pdf,"TrickingLLMsintoDisobedienceUnderstanding,Analyzing,andPreventingJailbreaks.pdf",C:\Users\zhangyongting\Desktop\work\openreview\pdf
26,Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations,/attachment?id=WngUxIgvf_&name=pdf,JailbreakandGuardAlignedLanguageModelswithOnlyFewInContextDemonstrations.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
27,Shield and Spear: Jailbreaking Aligned LLMs with Generative Prompting,/attachment?id=1xhAJSjG45&name=pdf,ShieldandSpearJailbreakingAlignedLLMswithGenerativePrompting.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
28,False Sense of Security: A Study on the Effectivity of Jailbreak Detection in Banking Apps,/attachment?id=2ijn-NvtgUT&name=pdf,FalseSenseofSecurityAStudyontheEffectivityofJailbreakDetectioninBankingApps.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
29,Jailbreaking your Reference Lists: the OpenCitations Project Strikes Again,/attachment?id=sz-Vv3ioka&name=pdf,JailbreakingyourReferenceListstheOpenCitationsProjectStrikesAgain.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
30,VJPrompt: VAE-like Jailbreaking Prompt Strategy to Unmask Deceptive Power of Large Language Models,/attachment?id=DXfjOFFZ1E&name=pdf,VJPromptVAElikeJailbreakingPromptStrategytoUnmaskDeceptivePowerofLargeLanguageModels.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
31,On the Adversarial Robustness of Multi-Modal Foundation Models,/attachment?id=Iyc53R2eQc&name=pdf,OntheAdversarialRobustnessofMultiModalFoundationModels.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
32,Baseline Defenses for Adversarial Attacks Against Aligned Language Models,/attachment?id=ejYMtn8oSaG&name=pdf,BaselineDefensesforAdversarialAttacksAgainstAlignedLanguageModels.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
33,Fundamental Limitations of Alignment in Large Language Models,/attachment?id=s0c2fL4bLcV&name=pdf,FundamentalLimitationsofAlignmentinLargeLanguageModels.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
34,Language Model Unalignment: Parametric Red-Teaming to Expose Hidden Harms and Biases,/attachment?id=Ce6KowH39Gk&name=pdf,LanguageModelUnalignmentParametricRedTeamingtoExposeHiddenHarmsandBiases.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
35,Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment,/attachment?id=jkcHYEfPv3&name=pdf,RedTeamingLargeLanguageModelsusingChainofUtterancesforSafetyAlignment.pdf,C:\Users\zhangyongting\Desktop\work\openreview\pdf
